{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f75f80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215007f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCROLL_PAUSE_TIME = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdd8663",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_sentences(responses, sentences, conversation_id):\n",
    "    print(\"Conversation ID: {}\".format(conversation_id))\n",
    "    \n",
    "#     for index, row in sentences.iterrows():\n",
    "#         if row[\"conversation_id\"] == conversation_id:\n",
    "#             sentences.loc[index, \"sentence\"] = responses[index][(row[\"start_index\"] - 1) : \n",
    "#                                                                 (row[\"end_index\"] - 1)]\n",
    "#             print(sentences.loc[index, \"sentence\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaaf6790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: may need to remove \\n characters depending on semantics of how they parsed sentences. Also\n",
    "# may need to replace the unicode vestigial characters with empty string instead of space.\n",
    "\n",
    "def scrape_url(conversation_url):\n",
    "    print(\"Conversation URL: {}\".format(conversation_url))\n",
    "        \n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    chrome_options.add_argument(\"--incognito\")\n",
    "    chrome_options.add_argument(\"headless\")\n",
    "\n",
    "    driver = webdriver.Chrome(options = chrome_options)\n",
    "    driver.get(conversation_url + \"?sort_by=oldest\")\n",
    "    \n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(SCROLL_PAUSE_TIME)\n",
    "    new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    while last_height != new_height:\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(SCROLL_PAUSE_TIME)\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        last_height = new_height\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source)\n",
    "    \n",
    "    original_post = soup.find(\"div\", {\"id\" : \"subject_msg\"})\n",
    "    post_list = soup.find(\"div\", {\"id\" : \"post_show_\" + conversation_url.split(\"/\")[-1]})\n",
    "    post_contents = post_list.find_all(\"div\", {\"class\" : \"resp_body\"})\n",
    "    post_user_data = post_list.find_all(\"div\", {\"class\" : \"username\"})\n",
    "    \n",
    "#     responses = [original_post.text.replace(u\"\\xa0\", u\" \").strip()]\n",
    "#     for response in :\n",
    "#         responses.append(response.text.replace(u\"\\xa0\", u\" \").strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd46febf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_conversations(disease):\n",
    "    conversations = pd.read_csv(\"gold_standard/conversations/\" + disease + \".tsv\", delimiter = \"\\t\")\n",
    "    posts = pd.read_csv(\"gold_standard/posts/\" + disease + \".tsv\", delimiter = \"\\t\")\n",
    "    expected_posts = posts.groupby(\"conversation_id\")[\"post_id\"].count()\n",
    "    sentences = pd.read_csv(\"gold_standard/sentences/\" + disease + \".tsv\", delimiter = \"\\t\")\n",
    "    \n",
    "    for index, row in conversations.iterrows():\n",
    "        responses = scrape_url(row[\"url\"])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50e2a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def driver():\n",
    "    diseases = pd.read_csv(\"gold_standard/diseases/diseases.tsv\", delimiter = \"\\t\")\n",
    "    \n",
    "    for disease in diseases[\"disease_id\"]:\n",
    "        print(\"Disease ID: {}\".format(disease))\n",
    "        scrape_conversations(disease)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b949192",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
